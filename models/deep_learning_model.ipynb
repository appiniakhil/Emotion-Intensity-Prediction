{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "#for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "#for nlp\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#for regression model\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#for evaluation\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label  intensity\n",
       "0  10857  @ZubairSabirPTI  pls dont insult the word 'Molna'  anger      0.479\n",
       "1  10858  @ArcticFantasy I would have almost took offens...  anger      0.458\n",
       "2  10859  @IllinoisLoyalty that Rutgers game was an abom...  anger      0.562\n",
       "3  10860  @CozanGaming that's what lisa asked before she...  anger      0.500\n",
       "4  10861  Sometimes I get mad over something so minuscul...  anger      0.708"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train data for different emotions\n",
    "cols = ['id', 'text', 'label', 'intensity']\n",
    "\n",
    "anger_ratings = pd.read_csv('data/anger-ratings.csv', header=0, names=cols)\n",
    "fear_ratings = pd.read_csv('data/fear-ratings.csv', header=0, names=cols)\n",
    "sad_ratings = pd.read_csv('data/sadness-ratings.csv', header=0, names=cols)\n",
    "joy_ratings = pd.read_csv('data/joy-ratings.csv', header=0, names=cols)\n",
    "\n",
    "# Display the first few rows of the joy_train DataFrame\n",
    "anger_ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "fear       2252\n",
      "anger      1701\n",
      "joy        1616\n",
      "sadness    1533\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Frames contain anger_ratings, fear_ratings, sad_ratings, joy_ratings\n",
    "frames = [anger_ratings, fear_ratings, sad_ratings, joy_ratings]\n",
    "data_training = pd.concat(frames)\n",
    "data_training.reset_index(inplace=True)\n",
    "\n",
    "# Filter out rows with label equal to 4\n",
    "data_training = data_training[data_training['label'] != 4]\n",
    "\n",
    "# Rename the label \"Label\" to the actual emotion labels\n",
    "data_training['label'] = data_training['label'].replace({'Label': 'fear'})\n",
    "\n",
    "# Reset index after filtering and renaming\n",
    "data_training.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check label value counts after removal\n",
    "print(data_training['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10859</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10860</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10861</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     id                                               text  label  \\\n",
       "0      0  10857  @ZubairSabirPTI  pls dont insult the word 'Molna'  anger   \n",
       "1      1  10858  @ArcticFantasy I would have almost took offens...  anger   \n",
       "2      2  10859  @IllinoisLoyalty that Rutgers game was an abom...  anger   \n",
       "3      3  10860  @CozanGaming that's what lisa asked before she...  anger   \n",
       "4      4  10861  Sometimes I get mad over something so minuscul...  anger   \n",
       "\n",
       "   intensity  \n",
       "0      0.479  \n",
       "1      0.458  \n",
       "2      0.562  \n",
       "3      0.500  \n",
       "4      0.708  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punc_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>14</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10859</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10860</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>16</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10861</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>25</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     id                                               text  label  \\\n",
       "0      0  10857  @ZubairSabirPTI  pls dont insult the word 'Molna'  anger   \n",
       "1      1  10858  @ArcticFantasy I would have almost took offens...  anger   \n",
       "2      2  10859  @IllinoisLoyalty that Rutgers game was an abom...  anger   \n",
       "3      3  10860  @CozanGaming that's what lisa asked before she...  anger   \n",
       "4      4  10861  Sometimes I get mad over something so minuscul...  anger   \n",
       "\n",
       "   intensity  word_count  char_count  punc_count  \n",
       "0      0.479           7          42           3  \n",
       "1      0.458          14          68           1  \n",
       "2      0.562          20          95           4  \n",
       "3      0.500          16          75           6  \n",
       "4      0.708          25         109           0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = string.punctuation\n",
    "data_training['word_count'] = data_training['text'].apply(lambda x:len(x.split()))\n",
    "data_training['char_count'] = data_training['text'].apply(lambda x:len(x.replace(' ','')))\n",
    "data_training['punc_count'] = data_training['text'].apply(lambda x:len([a for a in x if a in punc]))\n",
    "data_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\appin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "mention_pattern = r'@[A-Za-z0-9_]+'\n",
    "url_pattern = r'https?://[A-Za-z0-9./]+'\n",
    "number_pattern = r'[0-9]+'\n",
    "\n",
    "combined_pattern = re.compile(f\"({'|'.join([mention_pattern, url_pattern, number_pattern])})\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tweet_cleaner(data_frame):\n",
    "    print('Cleaning and parsing the tweets...\\n')\n",
    "    clean_data = []\n",
    "    \n",
    "    for index, row in data_frame.iterrows():\n",
    "        cleaned_text = re.sub(combined_pattern, '', row.text)\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        words = word_tokenize(cleaned_text)\n",
    "        filtered_words = [w for w in words if w not in stop_words]\n",
    "        cleaned_sentence = ' '.join(filtered_words).strip()\n",
    "        clean_data.append((cleaned_sentence, row.label, row.intensity))  # Include intensity value\n",
    "    print('Done!')\n",
    "    return clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "clean_data_training_list = tweet_cleaner(data_training)\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "clean_data_training_df = pd.DataFrame(clean_data_training_list, columns=['cleaned_text', 'label', 'intensity'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "clean_data_training_df.to_csv('cleaned_data_training.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\python311\\lib\\site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\python311\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\appin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\appin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\mask_rcnn-2.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup, BertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cleaned_data_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pls dont insult word 'molna '</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would almost took offense actually snapped</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rutgers game abomination . affront god man . m...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'s lisa asked started raging , 'can call ? ' heh</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sometimes get mad something minuscule try ruin...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>'s lack company liveliness makes bored .</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>quinn 's short hair makes sad . # glee</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>hate overthinking e v e r h n g like jus ' wan...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>people cheer sports teams completely outside n...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>'re pos rejoicing someone 's death .</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text  label  intensity\n",
       "0                         pls dont insult word 'molna '  anger      0.479\n",
       "1            would almost took offense actually snapped  anger      0.458\n",
       "2     rutgers game abomination . affront god man . m...  anger      0.562\n",
       "3      's lisa asked started raging , 'can call ? ' heh  anger      0.500\n",
       "4     sometimes get mad something minuscule try ruin...  anger      0.708\n",
       "...                                                 ...    ...        ...\n",
       "7097           's lack company liveliness makes bored .    joy      0.058\n",
       "7098             quinn 's short hair makes sad . # glee    joy      0.040\n",
       "7099  hate overthinking e v e r h n g like jus ' wan...    joy      0.040\n",
       "7100  people cheer sports teams completely outside n...    joy      0.020\n",
       "7101               're pos rejoicing someone 's death .    joy      0.019\n",
       "\n",
       "[7102 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts\n",
    "# words = data.words.tolist()\n",
    "words = [str(cleaned_text) for cleaned_text in data.cleaned_text.tolist()]\n",
    "data_1 = tokenizer.batch_encode_plus(words, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "\n",
    "# Prepare the dataset\n",
    "vad_scores1 = torch.tensor(data[['intensity']].values, dtype=torch.float32)\n",
    "dataset = TensorDataset(data_1[\"input_ids\"], data_1[\"attention_mask\"], vad_scores1)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset,test_dataset = random_split(dataset, [train_size, val_size,test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size_dataset = 16\n",
    "num_workers = 0\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_dataset, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_dataset, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_dataset, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the VADModel Class and Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VADModel class\n",
    "class VADModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VADModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc = nn.Linear(768, 1)  # 768 is the output size of BERT base model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        vad_scores_pred = self.fc(pooled_output)\n",
    "        return vad_scores_pred\n",
    "\n",
    "# Create an instance of VADModel\n",
    "model = VADModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function, Optimizer, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339a4782106c49798d03125cd1266036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5, Loss:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Loss = 0.0346, MSE = 0.0022\n",
      "Validation MSE: 0.0017\n",
      "Validation Loss: 0.0262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a5876e1361430b8d1168e62d79c94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5, Loss:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: Loss = 0.0198, MSE = 0.0012\n",
      "Validation MSE: 0.0015\n",
      "Validation Loss: 0.0229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c8c8d3785343cabdbfc4d6239b3337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5, Loss:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: Loss = 0.0113, MSE = 0.0007\n",
      "Validation MSE: 0.0014\n",
      "Validation Loss: 0.0221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65248061fb4342248d13191604bf6d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5, Loss:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: Loss = 0.0058, MSE = 0.0004\n",
      "Validation MSE: 0.0015\n",
      "Validation Loss: 0.0233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491c4fe4e5fd4d7a855e6629a2c5e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5, Loss:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: Loss = 0.0033, MSE = 0.0002\n",
      "Validation MSE: 0.0015\n",
      "Validation Loss: 0.0233\n",
      "\n",
      "Average MSE across all epochs: 0.0009\n",
      "Average Loss across all epochs: 0.0150\n",
      "MAE: 0.1212\n",
      "RMSE: 0.1564\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "model.train()\n",
    "\n",
    "total_mse_across_epochs = 0.0\n",
    "total_loss_across_epochs = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    total_mse = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}, Loss: \", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        vad_scores = batch[2].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = loss_fn(outputs, vad_scores)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        mse = torch.mean(torch.square(outputs - vad_scores)).item()\n",
    "        total_mse += mse\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    epoch_mse = total_mse / len(train_loader.dataset)\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "\n",
    "    total_mse_across_epochs += epoch_mse\n",
    "    total_loss_across_epochs += epoch_loss\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Loss = {epoch_loss:.4f}, MSE = {epoch_mse:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_total_mse = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_input_ids = val_batch[0].to(device)\n",
    "            val_attention_mask = val_batch[1].to(device)\n",
    "            val_vad_scores = val_batch[2].to(device)\n",
    "\n",
    "            val_outputs = model(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
    "            val_loss = loss_fn(val_outputs, val_vad_scores)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "            val_mse = torch.mean(torch.square(val_outputs - val_vad_scores)).item()\n",
    "            val_total_mse += val_mse\n",
    "\n",
    "    val_epoch_mse = val_total_mse / len(val_loader.dataset)\n",
    "    val_epoch_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "    print(f\"Validation MSE: {val_epoch_mse:.4f}\")\n",
    "    print(f\"Validation Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "average_mse = total_mse_across_epochs / num_epochs\n",
    "average_loss = total_loss_across_epochs / num_epochs\n",
    "print(f\"\\nAverage MSE across all epochs: {average_mse:.4f}\")\n",
    "print(f\"Average Loss across all epochs: {average_loss:.4f}\")\n",
    "# Calculate MAE and RMSE\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_loader:\n",
    "        test_input_ids = test_batch[0].to(device)\n",
    "        test_attention_mask = test_batch[1].to(device)\n",
    "        test_vad_scores = test_batch[2].to(device)\n",
    "\n",
    "        test_outputs = model(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
    "        y_true.extend(test_vad_scores.cpu().numpy())\n",
    "        y_pred.extend(test_outputs.cpu().numpy())\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"deep_learning_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict VAD scores for a given text\n",
    "def predict_vad_scores(model, tokenizer, text, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"cleaned_data_training.csv\")  # Replace \"your_data.csv\" with your file path\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "predicted_scores = []\n",
    "for index, row in data.iterrows():\n",
    "    text = row['cleaned_text']  # Replace 'text_column_name' with the column containing text in your CSV\n",
    "    vad_scores = predict_vad_scores(model, tokenizer, text, device)\n",
    "    predicted_scores.append(vad_scores)\n",
    "\n",
    "# Add predicted scores to the DataFrame\n",
    "data['predicted_scores'] = predicted_scores\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "data.to_csv(\"predicted_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "      <th>predicted_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pls dont insult word 'molna '</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[[0.5012173]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would almost took offense actually snapped</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[[0.44910318]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rutgers game abomination . affront god man . m...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[[0.60562694]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'s lisa asked started raging , 'can call ? ' heh</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[[0.5181444]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sometimes get mad something minuscule try ruin...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[[0.6405146]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>'s lack company liveliness makes bored .</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.058</td>\n",
       "      <td>[[0.28966087]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>quinn 's short hair makes sad . # glee</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "      <td>[[0.15976156]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>hate overthinking e v e r h n g like jus ' wan...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "      <td>[[0.2919076]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>people cheer sports teams completely outside n...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[0.21450563]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>'re pos rejoicing someone 's death .</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.019</td>\n",
       "      <td>[[0.17529972]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text  label  intensity  \\\n",
       "0                         pls dont insult word 'molna '  anger      0.479   \n",
       "1            would almost took offense actually snapped  anger      0.458   \n",
       "2     rutgers game abomination . affront god man . m...  anger      0.562   \n",
       "3      's lisa asked started raging , 'can call ? ' heh  anger      0.500   \n",
       "4     sometimes get mad something minuscule try ruin...  anger      0.708   \n",
       "...                                                 ...    ...        ...   \n",
       "7097           's lack company liveliness makes bored .    joy      0.058   \n",
       "7098             quinn 's short hair makes sad . # glee    joy      0.040   \n",
       "7099  hate overthinking e v e r h n g like jus ' wan...    joy      0.040   \n",
       "7100  people cheer sports teams completely outside n...    joy      0.020   \n",
       "7101               're pos rejoicing someone 's death .    joy      0.019   \n",
       "\n",
       "     predicted_scores  \n",
       "0       [[0.5012173]]  \n",
       "1      [[0.44910318]]  \n",
       "2      [[0.60562694]]  \n",
       "3       [[0.5181444]]  \n",
       "4       [[0.6405146]]  \n",
       "...               ...  \n",
       "7097   [[0.28966087]]  \n",
       "7098   [[0.15976156]]  \n",
       "7099    [[0.2919076]]  \n",
       "7100   [[0.21450563]]  \n",
       "7101   [[0.17529972]]  \n",
       "\n",
       "[7102 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"predicted_data.csv\")\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
